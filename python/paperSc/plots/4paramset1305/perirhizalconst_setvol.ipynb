{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db1704b4-bd7a-4cb0-9f8c-019057b8f707",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pathresults = \"../../results/\"\n",
    "#pathresults = \"/DUMUXDune27/DUMUX/dumux-rosi/python/paperSc/results/\"\n",
    "data_file_delimiter = \",\"\n",
    "import re\n",
    "\n",
    "evalTime = 25.\n",
    "\n",
    "path2file_ = r'newMucil4p/{}_1476_{}_10to25_20mn_0s_128/'\n",
    "setIds = [17,38,44,85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a93c6cb-bbb5-4f8b-910e-611cbc6f30e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVal(mypath, filename, header=\"infer\",names = None):\n",
    "    fullpath = pathresults +mypath+filename\n",
    "    if names is None:\n",
    "        cst = pd.read_csv(fullpath,delimiter=data_file_delimiter, header = header).dropna(how= \"all\", axis=1)\n",
    "    else:\n",
    "        cst = pd.read_csv(fullpath,delimiter=data_file_delimiter, header = header, names = names).dropna(how= \"all\", axis=1)\n",
    "    return cst\n",
    "\n",
    "def getTimeLine(path2file, evalTime):\n",
    "    time = pd.read_csv(pathresults + path2file + \"time.txt\", names = [\"time\",\"Qlight\"])[\"time\"][1:] # because we have twice the initial value\n",
    "    time_diff = abs(np.array(time)-evalTime)\n",
    "    timeLineNeg = len(time_diff) - np.where(time_diff == min(time_diff))[0][0] \n",
    "    timeLinePos = len(time_diff) -timeLineNeg\n",
    "    print('timeLine',timeLineNeg,timeLinePos, min(time_diff) )\n",
    "    return timeLineNeg, timeLinePos\n",
    "    \n",
    "def get_last_line_as_numpy_array(file_path, timeLine,pos = False, dtype = float, verbose = False):\n",
    "    with open(pathresults +file_path, 'r') as file:\n",
    "        # Read all lines\n",
    "        lines = file.readlines()\n",
    "\n",
    "        # Check if there are any lines in the file\n",
    "        if not lines:\n",
    "            raise ValueError(\"The file is empty\")\n",
    "\n",
    "        # Get the last line\n",
    "        \n",
    "        try:\n",
    "            if pos:\n",
    "                last_line = lines[timeLine-1].strip()\n",
    "            else:\n",
    "                last_line = lines[-timeLine-1].strip()\n",
    "        except:\n",
    "            print('timeLine',file_path, len(lines)-timeLine, len(lines))\n",
    "            raise Exception\n",
    "\n",
    "        # Split the last line by commas and convert to NumPy array\n",
    "        array_from_last_line = np.array(last_line.split(','), dtype=dtype)\n",
    "        if verbose:\n",
    "            print(file_path, len(array_from_last_line), end=\", \")\n",
    "\n",
    "        return array_from_last_line\n",
    "\n",
    "def getCylIdx(path2file, timeLinePos):\n",
    "    fileName = \"rhizoSegsId.txt\"\n",
    "    fullpath = path2file+fileName\n",
    "    rhizoSegsId = get_last_line_as_numpy_array(fullpath, timeLinePos,pos=True, dtype = int, verbose = True)\n",
    "    print('rhizoSegsId',max(rhizoSegsId))\n",
    "    return rhizoSegsId\n",
    "    \n",
    "def list_files_with_prefix(folder_path, prefix):\n",
    "    file_names = []\n",
    "    for file_name in os.listdir(pathresults+folder_path):\n",
    "        if file_name.startswith(prefix):\n",
    "            file_names.append(file_name)\n",
    "    return file_names\n",
    "\n",
    "# cylinder max konz (per cell)\n",
    "def getData_(cid,gId,path2file, timeLineNeg):\n",
    "    fileName = \"cyl_val/Cyl_cellVol_\"+str(gId)+\".txt\"\n",
    "    cVol = get_last_line_as_numpy_array(path2file+fileName, timeLineNeg,pos= False, dtype = float)\n",
    "    if cid == volIdx:\n",
    "        return cVol\n",
    "    elif cid <= 9:\n",
    "        if cid <= 2:# == 0:\n",
    "            fileName = \"cyl_val/Cyl_watercontent_\"+str(gId)+\".txt\"\n",
    "            theta = get_last_line_as_numpy_array(path2file+fileName, timeLineNeg,pos= False,  dtype = float)\n",
    "            cVol *= theta#cm3 scv to cm3 water\n",
    "            if cid == 0:\n",
    "                return cVol\n",
    "        fileName = \"cyl_val/Cyl_content\"+str(cid)+\"_\"+str(gId)+\".txt\"\n",
    "        Q1 = get_last_line_as_numpy_array(path2file+fileName, timeLineNeg, pos= False, dtype = float)\n",
    "        konz = Q1/cVol #mol/cm3 or cm3/cm3\n",
    "        return konz\n",
    "    elif cid == coordId:\n",
    "        fileName = \"cyl_val/Cyl_coord_\"+str(gId)+\".txt\"\n",
    "        Q1 = get_last_line_as_numpy_array(path2file+fileName, timeLineNeg, pos= False, dtype = float)\n",
    "        return Q1\n",
    "    raise Exception\n",
    "\n",
    "nKonz = 9\n",
    "dictXYZ = {9:'X',10:'Y',11:'Z'}\n",
    "volIdx=12\n",
    "lenIdx=13\n",
    "stIdx=14\n",
    "orgIdId=15\n",
    "relLenId=16\n",
    "coordId = 17\n",
    "\n",
    "nToGet = coordId+1#elements + 3d coordinates of y , node+vol+len+st \n",
    "\n",
    "# baseline_1080_19_10to25_20mn_0s_128\n",
    "scenarios = [\"earlyDry\", \"baseline\", \"lateDry\"]\n",
    "exceptPset = []#[('baseline','19'),('baseline','47'),('baseline','83')]\n",
    "#result_list_compExcept = [path2file.format(scenario, str(setId)) for scenario, setId in exceptPsets]\n",
    "result_list_comp = [path2file_.format(scenario, str(setId)) for scenario in scenarios for setId in setIds if (scenario, str(setId)) not in exceptPset ]\n",
    "\n",
    "numPset = len(result_list_comp)\n",
    "allPSets = [ i for i in range(numPset) if i not in exceptPset]\n",
    "\n",
    "def getData():\n",
    "    \n",
    "    GiniAll = [[[] for i in range(numPset)] for ii in range(nToGet)]\n",
    "    \n",
    "    for pSet in allPSets:\n",
    "        print(pSet,end =\", \")\n",
    "        if True:\n",
    "\n",
    "        #try:\n",
    "            #path2file = 'none_55_'+str(pSet)+'_10to11_20mn_0s_5/'\n",
    "            path2file =result_list_comp[pSet]# \"forEGU\"+scenarios[pSet]+\"_1440_76_10to25_20mn_0s_128/\"\n",
    "\n",
    "            time = pd.read_csv(pathresults + path2file + \"time.txt\", names = [\"time\",\"Qlight\"])[\"time\"][1:] # because we have twice the initial value\n",
    "            timemax = int((max(time))*10)/10\n",
    "            print('timemax',timemax, timemax==25)\n",
    "            \n",
    "            if(timemax==25):\n",
    "                timeLineNeg, timeLinePos = getTimeLine(path2file, evalTime)\n",
    "                rr = getCylIdx(path2file, timeLinePos)\n",
    "\n",
    "                rr.sort()\n",
    "                print('(',len(rr),')',end =\", \")\n",
    "\n",
    "                for cid in range(nKonz):\n",
    "                    Ginits = np.array([getData_( cid, \n",
    "                                                gId,path2file, timeLineNeg) for gId in rr])          \n",
    "                    GiniAll[cid][pSet] = Ginits\n",
    "                for cid in range(nKonz,volIdx):\n",
    "                    nodes_ = get_last_line_as_numpy_array(path2file+\"nodes_\"+dictXYZ[cid]+\".txt\", timeLinePos,pos = True, dtype =float)\n",
    "                    GiniAll[cid][pSet] = nodes_[rr+1]#seg idx to y-idx\n",
    "                #cid = nToGet -1\n",
    "                Ginits = np.array([getData_( volIdx, gId,path2file, timeLineNeg) for gId in rr])\n",
    "                GiniAll[volIdx][pSet] = Ginits\n",
    "                \n",
    "                Ginits = np.array([getData_( coordId, gId,path2file, timeLineNeg) for gId in rr])\n",
    "                GiniAll[coordId][pSet] = Ginits\n",
    "                \n",
    "                \n",
    "                lens = get_last_line_as_numpy_array(path2file+\"length_Segs\"+\".txt\", timeLinePos,pos = True, dtype =float, verbose = True)\n",
    "                GiniAll[lenIdx][pSet] = lens[rr]\n",
    "                sts = get_last_line_as_numpy_array(path2file+\"subTypes\"+\".txt\", timeLinePos,pos = True, dtype =float, verbose = True)\n",
    "                assert len(sts) == len(lens)\n",
    "                GiniAll[stIdx][pSet] = sts[rr]\n",
    "\n",
    "                orgidPerNode = get_last_line_as_numpy_array(path2file+\"orgidPerNode.txt\", timeLinePos,pos = True, dtype =int, verbose = True)\n",
    "                globalNodeId = get_last_line_as_numpy_array(path2file+\"globalNodeId.txt\", timeLinePos,pos = True, dtype =int, verbose = True)\n",
    "                parentNidx = get_last_line_as_numpy_array(path2file+\"parentNidx.txt\", timeLinePos, pos = True,dtype =int, verbose = True)\n",
    "                ot_orgs = get_last_line_as_numpy_array(path2file+\"ot_orgs.txt\", timeLinePos,pos = True, dtype =int, verbose = True)\n",
    "                id_orgs = get_last_line_as_numpy_array(path2file+\"id_orgs.txt\", timeLinePos, pos = True,\n",
    "                                                       dtype =int, verbose = True)\n",
    "                id_roots = id_orgs[np.where(ot_orgs==2)]\n",
    "\n",
    "                org2basenode = dict(zip(id_orgs, parentNidx))\n",
    "                #org2ot = dict(zip(id_orgs, ot_orgs))\n",
    "                isRoot = np.array([oo in id_roots for oo in orgidPerNode])\n",
    "\n",
    "                orgidPerRoot = orgidPerNode[np.where(isRoot)]\n",
    "                globalNodeIdroot =  globalNodeId[np.where(isRoot)]        \n",
    "                segIdxRoot = np.array([rr for _, rr in enumerate(globalNodeIdroot) if rr != org2basenode[orgidPerRoot[_]]]) -1\n",
    "                orgIdxRoot = np.array([orgidPerRoot[_] for _, rr in enumerate(globalNodeIdroot) if rr != org2basenode[orgidPerRoot[_]]])\n",
    "                #segIdx2ot = dict(zip(segIdxRoot,orgIdxRoot))\n",
    "\n",
    "                relLens = np.zeros(len(segIdxRoot))\n",
    "                #lens = get_last_line_as_numpy_array(path2file+\"length_Segs\"+\".txt\", dtype =float)\n",
    "                for myorg in orgIdxRoot:\n",
    "                    thensegs = np.where(orgIdxRoot == myorg)#segIdxRoot[] \n",
    "                    lenSegs = GiniAll[lenIdx][pSet]\n",
    "                    relLens[thensegs] = np.cumsum(lenSegs[thensegs])\n",
    "\n",
    "\n",
    "                GiniAll[orgIdId][pSet] = orgIdxRoot\n",
    "                GiniAll[relLenId][pSet] = relLens\n",
    "\n",
    "            #except:\n",
    "            #    print('jump',end =\", \")\n",
    "\n",
    "    return GiniAll #cid pSet rr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9715b7e4-567e-42b5-8266-4a8aa8d438ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, timemax 25.0 True\n",
      "timeLine 1 1079 4.227729277772596e-13\n",
      "newMucil4p/earlyDry_1476_17_10to25_20mn_0s_128/rhizoSegsId.txt 783, rhizoSegsId 850\n",
      "( 783 ), newMucil4p/earlyDry_1476_17_10to25_20mn_0s_128/length_Segs.txt 851, newMucil4p/earlyDry_1476_17_10to25_20mn_0s_128/subTypes.txt 851, newMucil4p/earlyDry_1476_17_10to25_20mn_0s_128/orgidPerNode.txt 851, newMucil4p/earlyDry_1476_17_10to25_20mn_0s_128/globalNodeId.txt 851, newMucil4p/earlyDry_1476_17_10to25_20mn_0s_128/parentNidx.txt 376, newMucil4p/earlyDry_1476_17_10to25_20mn_0s_128/ot_orgs.txt 376, newMucil4p/earlyDry_1476_17_10to25_20mn_0s_128/id_orgs.txt 376, 1, timemax 20.3 False\n",
      "2, timemax 25.0 True\n",
      "timeLine 1 1079 4.227729277772596e-13\n",
      "newMucil4p/earlyDry_1476_44_10to25_20mn_0s_128/rhizoSegsId.txt 782, rhizoSegsId 849\n",
      "( 782 ), newMucil4p/earlyDry_1476_44_10to25_20mn_0s_128/length_Segs.txt 850, newMucil4p/earlyDry_1476_44_10to25_20mn_0s_128/subTypes.txt 850, newMucil4p/earlyDry_1476_44_10to25_20mn_0s_128/orgidPerNode.txt 850, newMucil4p/earlyDry_1476_44_10to25_20mn_0s_128/globalNodeId.txt 850, newMucil4p/earlyDry_1476_44_10to25_20mn_0s_128/parentNidx.txt 375, newMucil4p/earlyDry_1476_44_10to25_20mn_0s_128/ot_orgs.txt 375, newMucil4p/earlyDry_1476_44_10to25_20mn_0s_128/id_orgs.txt 375, 3, timemax 25.0 True\n",
      "timeLine 1 1079 4.227729277772596e-13\n",
      "newMucil4p/earlyDry_1476_85_10to25_20mn_0s_128/rhizoSegsId.txt 1189, rhizoSegsId 1264\n",
      "( 1189 ), newMucil4p/earlyDry_1476_85_10to25_20mn_0s_128/length_Segs.txt 1265, newMucil4p/earlyDry_1476_85_10to25_20mn_0s_128/subTypes.txt 1265, newMucil4p/earlyDry_1476_85_10to25_20mn_0s_128/orgidPerNode.txt 1265, newMucil4p/earlyDry_1476_85_10to25_20mn_0s_128/globalNodeId.txt 1265, newMucil4p/earlyDry_1476_85_10to25_20mn_0s_128/parentNidx.txt 596, newMucil4p/earlyDry_1476_85_10to25_20mn_0s_128/ot_orgs.txt 596, newMucil4p/earlyDry_1476_85_10to25_20mn_0s_128/id_orgs.txt 596, 4, timemax 25.0 True\n",
      "timeLine 1 1079 4.227729277772596e-13\n",
      "newMucil4p/baseline_1476_17_10to25_20mn_0s_128/rhizoSegsId.txt 1072, rhizoSegsId 1145\n",
      "( 1072 ), newMucil4p/baseline_1476_17_10to25_20mn_0s_128/length_Segs.txt 1146, newMucil4p/baseline_1476_17_10to25_20mn_0s_128/subTypes.txt 1146, newMucil4p/baseline_1476_17_10to25_20mn_0s_128/orgidPerNode.txt 1146, newMucil4p/baseline_1476_17_10to25_20mn_0s_128/globalNodeId.txt 1146, newMucil4p/baseline_1476_17_10to25_20mn_0s_128/parentNidx.txt 527, newMucil4p/baseline_1476_17_10to25_20mn_0s_128/ot_orgs.txt 527, newMucil4p/baseline_1476_17_10to25_20mn_0s_128/id_orgs.txt 527, 5, timemax 25.0 True\n",
      "timeLine 1 1079 4.227729277772596e-13\n",
      "newMucil4p/baseline_1476_38_10to25_20mn_0s_128/rhizoSegsId.txt 1053, rhizoSegsId 1126\n",
      "( 1053 ), newMucil4p/baseline_1476_38_10to25_20mn_0s_128/length_Segs.txt 1127, newMucil4p/baseline_1476_38_10to25_20mn_0s_128/subTypes.txt 1127, newMucil4p/baseline_1476_38_10to25_20mn_0s_128/orgidPerNode.txt 1127, newMucil4p/baseline_1476_38_10to25_20mn_0s_128/globalNodeId.txt 1127, newMucil4p/baseline_1476_38_10to25_20mn_0s_128/parentNidx.txt 516, newMucil4p/baseline_1476_38_10to25_20mn_0s_128/ot_orgs.txt 516, newMucil4p/baseline_1476_38_10to25_20mn_0s_128/id_orgs.txt 516, 6, timemax 25.0 True\n",
      "timeLine 1 1079 4.227729277772596e-13\n",
      "newMucil4p/baseline_1476_44_10to25_20mn_0s_128/rhizoSegsId.txt 1066, rhizoSegsId 1139\n",
      "( 1066 ), newMucil4p/baseline_1476_44_10to25_20mn_0s_128/length_Segs.txt 1140, newMucil4p/baseline_1476_44_10to25_20mn_0s_128/subTypes.txt 1140, newMucil4p/baseline_1476_44_10to25_20mn_0s_128/orgidPerNode.txt 1140, newMucil4p/baseline_1476_44_10to25_20mn_0s_128/globalNodeId.txt 1140, newMucil4p/baseline_1476_44_10to25_20mn_0s_128/parentNidx.txt 523, newMucil4p/baseline_1476_44_10to25_20mn_0s_128/ot_orgs.txt 523, newMucil4p/baseline_1476_44_10to25_20mn_0s_128/id_orgs.txt 523, 7, timemax 25.0 True\n",
      "timeLine 1 1079 4.227729277772596e-13\n",
      "newMucil4p/baseline_1476_85_10to25_20mn_0s_128/rhizoSegsId.txt 1380, rhizoSegsId 1460\n",
      "( 1380 ), newMucil4p/baseline_1476_85_10to25_20mn_0s_128/length_Segs.txt 1461, newMucil4p/baseline_1476_85_10to25_20mn_0s_128/subTypes.txt 1461, newMucil4p/baseline_1476_85_10to25_20mn_0s_128/orgidPerNode.txt 1461, newMucil4p/baseline_1476_85_10to25_20mn_0s_128/globalNodeId.txt 1461, newMucil4p/baseline_1476_85_10to25_20mn_0s_128/parentNidx.txt 694, newMucil4p/baseline_1476_85_10to25_20mn_0s_128/ot_orgs.txt 694, newMucil4p/baseline_1476_85_10to25_20mn_0s_128/id_orgs.txt 694, 8, timemax 25.0 True\n",
      "timeLine 1 1079 4.227729277772596e-13\n",
      "newMucil4p/lateDry_1476_17_10to25_20mn_0s_128/rhizoSegsId.txt 814, rhizoSegsId 877\n",
      "( 814 ), newMucil4p/lateDry_1476_17_10to25_20mn_0s_128/length_Segs.txt 878, newMucil4p/lateDry_1476_17_10to25_20mn_0s_128/subTypes.txt 878, newMucil4p/lateDry_1476_17_10to25_20mn_0s_128/orgidPerNode.txt 878, newMucil4p/lateDry_1476_17_10to25_20mn_0s_128/globalNodeId.txt 878, newMucil4p/lateDry_1476_17_10to25_20mn_0s_128/parentNidx.txt 361, newMucil4p/lateDry_1476_17_10to25_20mn_0s_128/ot_orgs.txt 361, newMucil4p/lateDry_1476_17_10to25_20mn_0s_128/id_orgs.txt 361, 9, timemax 25.0 True\n",
      "timeLine 1 1079 4.227729277772596e-13\n",
      "newMucil4p/lateDry_1476_38_10to25_20mn_0s_128/rhizoSegsId.txt 827, rhizoSegsId 890\n",
      "( 827 ), newMucil4p/lateDry_1476_38_10to25_20mn_0s_128/length_Segs.txt 891, newMucil4p/lateDry_1476_38_10to25_20mn_0s_128/subTypes.txt 891, newMucil4p/lateDry_1476_38_10to25_20mn_0s_128/orgidPerNode.txt 891, newMucil4p/lateDry_1476_38_10to25_20mn_0s_128/globalNodeId.txt 891, newMucil4p/lateDry_1476_38_10to25_20mn_0s_128/parentNidx.txt 374, newMucil4p/lateDry_1476_38_10to25_20mn_0s_128/ot_orgs.txt 374, newMucil4p/lateDry_1476_38_10to25_20mn_0s_128/id_orgs.txt 374, 10, timemax 25.0 True\n",
      "timeLine 1 1079 4.227729277772596e-13\n",
      "newMucil4p/lateDry_1476_44_10to25_20mn_0s_128/rhizoSegsId.txt 791, rhizoSegsId 853\n",
      "( 791 ), newMucil4p/lateDry_1476_44_10to25_20mn_0s_128/length_Segs.txt 854, newMucil4p/lateDry_1476_44_10to25_20mn_0s_128/subTypes.txt 854, newMucil4p/lateDry_1476_44_10to25_20mn_0s_128/orgidPerNode.txt 854, newMucil4p/lateDry_1476_44_10to25_20mn_0s_128/globalNodeId.txt 854, newMucil4p/lateDry_1476_44_10to25_20mn_0s_128/parentNidx.txt 344, newMucil4p/lateDry_1476_44_10to25_20mn_0s_128/ot_orgs.txt 344, newMucil4p/lateDry_1476_44_10to25_20mn_0s_128/id_orgs.txt 344, 11, timemax 25.0 True\n",
      "timeLine 1 1079 4.227729277772596e-13\n",
      "newMucil4p/lateDry_1476_85_10to25_20mn_0s_128/rhizoSegsId.txt 1123, rhizoSegsId 1190\n",
      "( 1123 ), newMucil4p/lateDry_1476_85_10to25_20mn_0s_128/length_Segs.txt 1191, newMucil4p/lateDry_1476_85_10to25_20mn_0s_128/subTypes.txt 1191, newMucil4p/lateDry_1476_85_10to25_20mn_0s_128/orgidPerNode.txt 1191, newMucil4p/lateDry_1476_85_10to25_20mn_0s_128/globalNodeId.txt 1191, newMucil4p/lateDry_1476_85_10to25_20mn_0s_128/parentNidx.txt 532, newMucil4p/lateDry_1476_85_10to25_20mn_0s_128/ot_orgs.txt 532, newMucil4p/lateDry_1476_85_10to25_20mn_0s_128/id_orgs.txt 532, "
     ]
    }
   ],
   "source": [
    "\n",
    "GiniAll = getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a655a6-633c-4275-8077-ef71116bf566",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataInput =  [(scenario, str(setId)) for scenario in scenarios for setId in setIds if (scenario, str(setId)) not in exceptPset ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14524d76-c43f-4ab0-a3df-072d9d47d17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get param set\n",
    "outputvalsname =  ['wat','cs','cl','coa','cod','cca','ccd','css2','co2','yX','yY','yZ','vol','lenSeg','st','orgId','relLen']\n",
    "assert len(outputvalsname) == nToGet \n",
    "column_names = outputvalsname + ['scenario']\n",
    "df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "for pset, din in enumerate(dataInput):#range(numPset):\n",
    "    try:\n",
    "        N = GiniAll[0][pset].shape[0]\n",
    "        #assert N == 232\n",
    "        rows_df = pd.DataFrame()\n",
    "\n",
    "        for jj, outVn in enumerate(outputvalsname):\n",
    "            rows_df[outVn] = GiniAll[jj][pset]\n",
    "            #print('adding',jj,outVn,duplicated_rows_df.shape,len(GiniAll[jj][pset]))\n",
    "        rows_df['scenario'] = din[0]\n",
    "        rows_df['pSet'] = din[1]\n",
    "\n",
    "        df = pd.concat([df, rows_df], ignore_index=True)\n",
    "    except:\n",
    "        print('jump',pset, din)\n",
    "df['co'] = df['coa']+df['cod']\n",
    "df['cc'] = df['cca']+df['ccd']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38b",
   "language": "python",
   "name": "py38b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
