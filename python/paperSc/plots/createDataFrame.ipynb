{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d64aee40-f73c-4ec0-ac21-f29c377deb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pathresults = \"../results/\"\n",
    "#pathresults = \"/DUMUXDune27/DUMUX/dumux-rosi/python/paperSc/results/\"\n",
    "data_file_delimiter = \",\"\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342f7af9-52fe-4d56-aab0-f51faa74e297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23bf9002-f55d-48bf-80d9-137cbf405b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVal(mypath, filename, header=\"infer\",names = None):\n",
    "    fullpath = pathresults +mypath+filename\n",
    "    if names is None:\n",
    "        cst = pd.read_csv(fullpath,delimiter=data_file_delimiter, header = header).dropna(how= \"all\", axis=1)\n",
    "    else:\n",
    "        cst = pd.read_csv(fullpath,delimiter=data_file_delimiter, header = header, names = names).dropna(how= \"all\", axis=1)\n",
    "    return cst\n",
    "def get_last_line_as_numpy_array(file_path, dtype = float):\n",
    "    with open(pathresults +file_path, 'r') as file:\n",
    "        # Read all lines\n",
    "        lines = file.readlines()\n",
    "\n",
    "        # Check if there are any lines in the file\n",
    "        if not lines:\n",
    "            raise ValueError(\"The file is empty\")\n",
    "\n",
    "        # Get the last line\n",
    "        last_line = lines[-1].strip()\n",
    "\n",
    "        # Split the last line by commas and convert to NumPy array\n",
    "        array_from_last_line = np.array(last_line.split(','), dtype=dtype)\n",
    "\n",
    "        return array_from_last_line\n",
    "\n",
    "def list_files_with_prefix(folder_path, prefix):\n",
    "    file_names = []\n",
    "    for file_name in os.listdir(pathresults+folder_path):\n",
    "        if file_name.startswith(prefix):\n",
    "            file_names.append(file_name)\n",
    "    return file_names\n",
    "def getCylIdx(folder_path):\n",
    "    namelist = list_files_with_prefix(folder_path+\"cyl_val/\", \"Cyl_watercontent_\")\n",
    "    idxlist = np.full(len(namelist),-1,dtype = int)\n",
    "    for nn, nl in enumerate(namelist):\n",
    "        match = re.search(r'\\d+', nl)\n",
    "        number_str = match.group()\n",
    "        number_int = int(number_str)\n",
    "        idxlist[nn] = number_int\n",
    "    return idxlist\n",
    "# cylinder max konz (per cell)\n",
    "def getData_(cid,gId,path2file):\n",
    "    fileName = \"cyl_val/Cyl_cellVol_\"+str(gId)+\".txt\"\n",
    "    cVol = get_last_line_as_numpy_array(path2file+fileName, dtype = float)\n",
    "    if cid == volIdx:\n",
    "        return sum(cVol)\n",
    "    elif cid <= 9:\n",
    "        if cid <= 2:# == 0:\n",
    "            fileName = \"cyl_val/Cyl_watercontent_\"+str(gId)+\".txt\"\n",
    "            theta = get_last_line_as_numpy_array(path2file+fileName, dtype = float)\n",
    "            cVol *= theta#cm3 scv to cm3 water\n",
    "            if cid == 0:\n",
    "                return sum(cVol)\n",
    "        fileName = \"cyl_val/Cyl_content\"+str(cid)+\"_\"+str(gId)+\".txt\"\n",
    "        Q1 = get_last_line_as_numpy_array(path2file+fileName, dtype = float)\n",
    "        konz = sum(Q1)/sum(cVol) #mol/cm3 or cm3/cm3\n",
    "        return konz\n",
    "    raise Exception\n",
    "\n",
    "numPset = 99\n",
    "nKonz = 9\n",
    "dictXYZ = {9:'X',10:'Y',11:'Z'}\n",
    "volIdx=12\n",
    "lenIdx=13\n",
    "stIdx=14\n",
    "orgIdId=15\n",
    "relLenId=16\n",
    "\n",
    "nToGet = relLenId+1 #elements + 3d coordinates of y , node+vol+len+st \n",
    "\n",
    "exceptPset =[12, 13, 20, 22, 32, 39, 44, 61, 66, 67, 91]\n",
    "allPSets = [ i for i in range(numPset) if i not in exceptPset]\n",
    "\n",
    "def getData():\n",
    "    \n",
    "    GiniAll = [[[] for i in range(numPset)] for ii in range(nToGet)]\n",
    "    for pSet in allPSets:\n",
    "        print(pSet,end =\", \")\n",
    "\n",
    "        #path2file = 'none_55_'+str(pSet)+'_10to11_20mn_0s_5/'\n",
    "        path2file = 'noCss1none_1440_'+str(pSet)+'_10to11_20mn_0s_5/'\n",
    "        \n",
    "        rr = getCylIdx(path2file)\n",
    "        rr.sort()\n",
    "        print('(',len(rr),')',end =\", \")\n",
    "\n",
    "        for cid in range(nKonz):\n",
    "            Ginits = np.array([getData_( cid, gId,path2file) for gId in rr])          \n",
    "            GiniAll[cid][pSet] = Ginits\n",
    "        for cid in range(nKonz,volIdx):\n",
    "            nodes_ = get_last_line_as_numpy_array(path2file+\"nodes_\"+dictXYZ[cid]+\".txt\", dtype =float)\n",
    "            GiniAll[cid][pSet] = nodes_[rr+1]#seg idx to y-idx\n",
    "        #cid = nToGet -1\n",
    "        Ginits = np.array([getData_( volIdx, gId,path2file) for gId in rr])\n",
    "        GiniAll[volIdx][pSet] = Ginits\n",
    "        lens = get_last_line_as_numpy_array(path2file+\"length_Segs\"+\".txt\", dtype =float)\n",
    "        GiniAll[lenIdx][pSet] = lens[rr]\n",
    "        sts = get_last_line_as_numpy_array(path2file+\"subTypes\"+\".txt\", dtype =float)\n",
    "        assert len(sts) == len(lens)\n",
    "        GiniAll[stIdx][pSet] = sts[rr]\n",
    "        \n",
    "        orgidPerNode = get_last_line_as_numpy_array(path2file+\"orgidPerNode.txt\", dtype =int)\n",
    "        globalNodeId = get_last_line_as_numpy_array(path2file+\"globalNodeId.txt\", dtype =int)\n",
    "        parentNidx = get_last_line_as_numpy_array(path2file+\"parentNidx.txt\", dtype =int)\n",
    "        ot_orgs = get_last_line_as_numpy_array(path2file+\"ot_orgs.txt\", dtype =int)\n",
    "        id_orgs = get_last_line_as_numpy_array(path2file+\"id_orgs.txt\", dtype =int)\n",
    "        id_roots = id_orgs[np.where(ot_orgs==2)]\n",
    "        \n",
    "        org2basenode = dict(zip(id_orgs, parentNidx))\n",
    "        #org2ot = dict(zip(id_orgs, ot_orgs))\n",
    "        isRoot = np.array([oo in id_roots for oo in orgidPerNode])\n",
    "        \n",
    "        orgidPerRoot = orgidPerNode[np.where(isRoot)]\n",
    "        globalNodeIdroot =  globalNodeId[np.where(isRoot)]        \n",
    "        segIdxRoot = np.array([rr for _, rr in enumerate(globalNodeIdroot) if rr != org2basenode[orgidPerRoot[_]]]) -1\n",
    "        orgIdxRoot = np.array([orgidPerRoot[_] for _, rr in enumerate(globalNodeIdroot) if rr != org2basenode[orgidPerRoot[_]]])\n",
    "        #segIdx2ot = dict(zip(segIdxRoot,orgIdxRoot))\n",
    "        \n",
    "        relLens = np.zeros(len(segIdxRoot))\n",
    "        #lens = get_last_line_as_numpy_array(path2file+\"length_Segs\"+\".txt\", dtype =float)\n",
    "        for myorg in orgIdxRoot:\n",
    "            thensegs = np.where(orgIdxRoot == myorg)#segIdxRoot[] \n",
    "            lenSegs = GiniAll[lenIdx][pSet]\n",
    "            relLens[thensegs] = np.cumsum(lenSegs[thensegs])\n",
    "            \n",
    "            \n",
    "        GiniAll[orgIdId][pSet] = orgIdxRoot\n",
    "        GiniAll[relLenId][pSet] = relLens\n",
    "\n",
    "    return GiniAll #cid pSet rr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04036fbc-20b0-435a-8ece-b19b829b6f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( 238 ), "
     ]
    }
   ],
   "source": [
    "pSet = 0\n",
    "path2file = 'noCss1none_1440_'+str(pSet)+'_10to11_20mn_0s_5/'\n",
    "        \n",
    "rr = getCylIdx(path2file)\n",
    "rr.sort()\n",
    "print('(',len(rr),')',end =\", \")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a225df88-e1d2-4d29-923f-28725976cfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exceptPset =[12, 13, 20, 22, 32, 39, 44, 61, 66, 67, 91]\n",
    "allPSets = [ i for i in range(numPset) if i not in exceptPset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7924bb88-81aa-435d-a182-eaddbd611fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, ( 238 ), 1, ( 234 ), 2, ( 237 ), 3, ( 237 ), 4, ( 240 ), 5, ( 216 ), 6, ( 234 ), 7, ( 244 ), 8, ( 233 ), 9, ( 236 ), 10, ( 236 ), 11, ( 236 ), 14, ( 239 ), 15, ( 236 ), 16, ( 242 ), 17, ( 230 ), 18, ( 236 ), 19, ( 238 ), 21, ( 216 ), 23, ( 237 ), 24, ( 242 ), 25, ( 241 ), 26, ( 236 ), 27, ( 245 ), 28, ( 233 ), 29, ( 236 ), 30, ( 236 ), 31, ( 238 ), 33, ( 234 ), 34, ( 249 ), 35, ( 244 ), 36, ( 236 ), 37, ( 237 ), 38, ( 236 ), 40, ( 221 ), 41, ( 242 ), 42, ( 237 ), 43, ( 244 ), 45, ( 237 ), 46, ( 237 ), 47, ( 244 ), 48, ( 234 ), 49, ( 244 ), 50, ( 242 ), 51, ( 244 ), 52, ( 239 ), 53, ( 221 ), 54, ( 234 ), 55, ( 244 ), 56, ( 244 ), 57, ( 220 ), 58, ( 240 ), 59, ( 237 ), 60, ( 244 ), 62, ( 249 ), 63, ( 236 ), 64, ( 240 ), 65, ( 234 ), 68, ( 234 ), 69, ( 237 ), 70, ( 244 ), 71, ( 236 ), 72, ( 242 ), 73, ( 244 ), 74, ( 206 ), 75, ( 244 ), 76, ( 236 ), 77, ( 234 ), 78, ( 242 ), 79, ( 237 ), 80, ( 240 ), 81, ( 236 ), 82, ( 238 ), 83, ( 244 ), 84, ( 230 ), 85, ( 244 ), 86, ( 244 ), 87, ( 239 ), 88, ( 244 ), 89, ( 236 ), 90, ( 236 ), 92, ( 244 ), 93, ( 242 ), 94, ( 244 ), 95, ( 238 ), 96, ( 238 ), 97, ( 244 ), 98, ( 238 ), "
     ]
    }
   ],
   "source": [
    "GiniAll = getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "10efd9e7-4f14-49bd-b978-30e688e1384f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1126/1273250247.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  assert np.array(GiniAll).shape == (nToGet, numPset, 232) #all same shape\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[131], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(GiniAll)\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (nToGet, numPset, \u001b[38;5;241m232\u001b[39m) \u001b[38;5;66;03m#all same shape\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#assert np.array(GiniAll).shape == (nToGet, numPset, 232) # some have a couple of segments more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80bd6820-d8bd-40b6-9753-0df6c58e4069",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_498436/2873905747.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np.array(GiniAll).shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17, 99)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(GiniAll).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3d081bb-59cd-418b-a452-8a7ca1620904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get param set\n",
    "paramsets =  pd.read_csv('../output_random_rows.csv')\n",
    "paramsets = paramsets.drop(paramsets.columns.tolist()[-1],axis=1)\n",
    "paramsets['k_C,S'] /=paramsets['theta']\n",
    "paramsets['k_O,S'] /=paramsets['theta']\n",
    "paramsets.drop(labels='theta', inplace=True, axis=1)\n",
    "outputvalsname =  ['wat','cs','cl','coa','cod','cca','ccd','css2','co2','yX','yY','yZ','vol','lenSeg','st','orgId','relLen']\n",
    "assert len(outputvalsname) == nToGet \n",
    "column_names = outputvalsname + paramsets.columns.tolist()+['pSet']\n",
    "df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "for pset in allPSets:#range(numPset):\n",
    "    N = GiniAll[0][pset].shape[0]\n",
    "    #assert N == 232\n",
    "    rows_to_duplicate_df = pd.DataFrame(paramsets.iloc[pset]).T\n",
    "    duplicated_rows_df = rows_to_duplicate_df.loc[np.repeat(rows_to_duplicate_df.index.values, N)]\n",
    "    # Duplicate the specific rows N times\n",
    "    #print('init dupl row shape',duplicated_rows_df.shape)\n",
    "    for jj, outVn in enumerate(outputvalsname):\n",
    "        duplicated_rows_df[outVn] = GiniAll[jj][pset]\n",
    "        #print('adding',jj,outVn,duplicated_rows_df.shape,len(GiniAll[jj][pset]))\n",
    "    duplicated_rows_df['pSet'] = pset\n",
    "    \n",
    "    path2file = 'noCss1none_1440_'+str(pset)+'_10to11_20mn_0s_5/'\n",
    "    simTime = get_last_line_as_numpy_array(path2file+\"totalComputetime.txt\", dtype =float)[0]\n",
    "    \n",
    "    duplicated_rows_df['simTime'] = simTime\n",
    "    # Concatenate the original DataFrame with the duplicated specific rows\n",
    "    df = pd.concat([df, duplicated_rows_df], ignore_index=True)\n",
    "df['co'] = df['coa']+df['cod']\n",
    "df['cc'] = df['cca']+df['ccd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03ec30c9-4fbc-4633-bef4-28380f98e977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        22865.345728\n",
       "1        22865.345728\n",
       "2        22865.345728\n",
       "3        22865.345728\n",
       "4        22865.345728\n",
       "             ...     \n",
       "20896    28032.934171\n",
       "20897    28032.934171\n",
       "20898    28032.934171\n",
       "20899    28032.934171\n",
       "20900    28032.934171\n",
       "Name: simTime, Length: 20901, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['simTime'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c06e6c67-fce5-46e5-b0c3-c2d2b50c732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('./cyl10to11.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75a510d-9097-43b6-b1fd-585b28e0ccca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path2file = 'noCss1none_1440_'+str(0)+'_10to11_20mn_0s_5/'\n",
    "simTime = get_last_line_as_numpy_array(path2file+\"totalComputetime.txt\", dtype =float)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd87e52a-c86e-4703-a9c9-47baca650ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "simTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c38974d2-e24a-45f5-9f25-7a7ad829a34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9925.080730255693"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(df['simTime'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb3bb32-ebad-4d0f-b506-fd7d8b17a4a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38b",
   "language": "python",
   "name": "py38b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
