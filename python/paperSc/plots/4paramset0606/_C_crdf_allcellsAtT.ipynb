{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d64aee40-f73c-4ec0-ac21-f29c377deb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pathresults = \"../../results/\"\n",
    "#pathresults = \"/DUMUXDune27/DUMUX/dumux-rosi/python/paperSc/results/\"\n",
    "data_file_delimiter = \",\"\n",
    "import re\n",
    "\n",
    "evalTime = 25.\n",
    "\n",
    "path2file_ = r'getsrivssriset/{}_1476_{}_10to25_20mn_0s_64/'\n",
    "setIds = [5,44,61]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23bf9002-f55d-48bf-80d9-137cbf405b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getValOld(mypath, filename, header=\"infer\",names = None):\n",
    "    fullpath = pathresults +mypath+filename\n",
    "    if names is None:\n",
    "        cst = pd.read_csv(fullpath,delimiter=data_file_delimiter, header = header).dropna(how= \"all\", axis=1)\n",
    "    else:\n",
    "        cst = pd.read_csv(fullpath,delimiter=data_file_delimiter, header = header, names = names).dropna(how= \"all\", axis=1)\n",
    "    return cst\n",
    "\n",
    "def getVal(mypath, filename,dtype=float,extension='.txt', header=\"infer\",names = None):\n",
    "    fullpath = pathresults +mypath+filename\n",
    "    data_file_delimiter = \",\"\n",
    "    if names is None:\n",
    "        largest_column_count = 0\n",
    "        with open(fullpath, 'r') as temp_f:\n",
    "            lines = temp_f.readlines()\n",
    "        last_line = lines[-1].strip()\n",
    "        #print('last_line',last_line)\n",
    "        array_from_last_line = np.array(last_line.split(','), dtype=dtype)\n",
    "        largest_column_count = len(array_from_last_line)\n",
    "        names = [i for i in range(0, largest_column_count)]\n",
    "        cst = pd.read_csv(fullpath,delimiter=data_file_delimiter, \n",
    "                          header = header, names = names)\n",
    "        #print('cst',cst.shape)\n",
    "    else:\n",
    "        cst = pd.read_csv(fullpath,delimiter=data_file_delimiter, header = header, names = names)\n",
    "    return cst\n",
    "\n",
    "def getTimeLine(path2file, evalTime):\n",
    "    time = pd.read_csv(pathresults + path2file + \"time.txt\", names = [\"time\",\"Qlight\"])[\"time\"][1:] # because we have twice the initial value\n",
    "    time_diff = abs(np.array(time)-evalTime)\n",
    "    timeLineNeg = len(time_diff) - np.where(time_diff == min(time_diff))[0][0] \n",
    "    timeLinePos = len(time_diff) -timeLineNeg\n",
    "    print('timeLine',timeLineNeg,timeLinePos, min(time_diff) )\n",
    "    return timeLineNeg, timeLinePos\n",
    "\n",
    "\n",
    "def get_line_X_as_numpy_array(file_path, timeLine,pos = False, dtype = float, verbose = False):\n",
    "    with open(pathresults +file_path, 'r') as file:\n",
    "        # Read all lines\n",
    "        lines = file.readlines()\n",
    "\n",
    "        # Check if there are any lines in the file\n",
    "        if not lines:\n",
    "            raise ValueError(\"The file is empty\")\n",
    "\n",
    "        # Get the last line\n",
    "        \n",
    "        try:\n",
    "            if pos:\n",
    "                last_line = lines[timeLine-1].strip()\n",
    "            else:\n",
    "                last_line = lines[-timeLine-1].strip()\n",
    "        except:\n",
    "            print('timeLine',file_path, len(lines)-timeLine, len(lines))\n",
    "            raise Exception\n",
    "\n",
    "        # Split the last line by commas and convert to NumPy array\n",
    "        array_from_last_line = np.array(last_line.split(','), dtype=dtype)\n",
    "        if verbose:\n",
    "            print(file_path, len(array_from_last_line), end=\", \")\n",
    "\n",
    "        return array_from_last_line\n",
    "\n",
    "def get_last_line_as_numpy_array(file_path, timeLine,pos = False, dtype = float, verbose = False):\n",
    "    with open(pathresults +file_path, 'r') as file:\n",
    "        # Read all lines\n",
    "        lines = file.readlines()\n",
    "\n",
    "        # Check if there are any lines in the file\n",
    "        if not lines:\n",
    "            raise ValueError(\"The file is empty\")\n",
    "\n",
    "        # Get the last line\n",
    "        \n",
    "        try:\n",
    "            if pos:\n",
    "                last_line = lines[timeLine-1].strip()\n",
    "            else:\n",
    "                last_line = lines[-timeLine-1].strip()\n",
    "        except:\n",
    "            print('timeLine',file_path, len(lines)-timeLine, len(lines))\n",
    "            raise Exception\n",
    "\n",
    "        # Split the last line by commas and convert to NumPy array\n",
    "        array_from_last_line = np.array(last_line.split(','), dtype=dtype)\n",
    "        if verbose:\n",
    "            print(file_path, len(array_from_last_line), end=\", \")\n",
    "\n",
    "        return array_from_last_line\n",
    "\n",
    "def getCylIdx(path2file, timeLinePos):\n",
    "    fileName = \"rhizoSegsId.txt\"\n",
    "    fullpath = path2file+fileName\n",
    "    rhizoSegsId = get_last_line_as_numpy_array(fullpath, timeLinePos,pos=True, dtype = int, verbose = True)\n",
    "    print('rhizoSegsId',max(rhizoSegsId))\n",
    "    return rhizoSegsId\n",
    "    \n",
    "def list_files_with_prefix(folder_path, prefix):\n",
    "    file_names = []\n",
    "    for file_name in os.listdir(pathresults+folder_path):\n",
    "        if file_name.startswith(prefix):\n",
    "            file_names.append(file_name)\n",
    "    return file_names\n",
    "\n",
    "# cylinder max konz (per cell)\n",
    "def getData_(cid,gId,path2file, timeLineNeg):\n",
    "    fileName = \"cyl_val/Cyl_cellVol_\"+str(gId)+\".txt\"\n",
    "    cVol = get_last_line_as_numpy_array(path2file+fileName, timeLineNeg,pos= False, dtype = float)\n",
    "    if cid == volIdx:\n",
    "        return cVol\n",
    "    elif cid <= 9:\n",
    "        if cid <= 2:# == 0:\n",
    "            fileName = \"cyl_val/Cyl_watercontent_\"+str(gId)+\".txt\"\n",
    "            theta = get_last_line_as_numpy_array(path2file+fileName, timeLineNeg,pos= False,  dtype = float)\n",
    "            cVol *= theta#cm3 scv to cm3 water\n",
    "            if cid == 0:\n",
    "                return cVol\n",
    "        fileName = \"cyl_val/Cyl_content\"+str(cid)+\"_\"+str(gId)+\".txt\"\n",
    "        Q1 = get_last_line_as_numpy_array(path2file+fileName, timeLineNeg, pos= False, dtype = float)\n",
    "        konz = Q1/cVol #mol/cm3 or cm3/cm3\n",
    "        return konz\n",
    "    elif cid == coordId:\n",
    "        fileName = \"cyl_val/Cyl_coord_\"+str(gId)+\".txt\"\n",
    "        Q1 = get_last_line_as_numpy_array(path2file+fileName, timeLineNeg, pos= False, dtype = float)\n",
    "        return Q1\n",
    "    raise Exception\n",
    "\n",
    "nKonz = 9\n",
    "dictXYZ = {9:'X',10:'Y',11:'Z'}\n",
    "volIdx=12\n",
    "lenIdx=13\n",
    "stIdx=14\n",
    "orgIdId=15\n",
    "relLenId=16\n",
    "coordId = 17\n",
    "\n",
    "nToGet = coordId+1#elements + 3d coordinates of y , node+vol+len+st \n",
    "\n",
    "# baseline_1080_19_10to25_20mn_0s_128\n",
    "scenarios = [\"earlyDry\", \"baseline\", \"lateDry\"]\n",
    "exceptPset = []#[('baseline','19'),('baseline','47'),('baseline','83')]\n",
    "#result_list_compExcept = [path2file.format(scenario, str(setId)) for scenario, setId in exceptPsets]\n",
    "result_list_comp = [path2file_.format(scenario, str(setId)) for scenario in scenarios for setId in setIds if (scenario, str(setId)) not in exceptPset ]\n",
    "\n",
    "numPset = len(result_list_comp)\n",
    "allPSets = [ i for i in range(numPset) if i not in exceptPset]\n",
    "\n",
    "def getData():\n",
    "    \n",
    "    GiniAll = [[[] for i in range(numPset)] for ii in range(nToGet)]\n",
    "    \n",
    "    for pSet in allPSets:\n",
    "        print(pSet,end =\", \")\n",
    "        if True:\n",
    "\n",
    "        #try:\n",
    "            #path2file = 'none_55_'+str(pSet)+'_10to11_20mn_0s_5/'\n",
    "            path2file =result_list_comp[pSet]# \"forEGU\"+scenarios[pSet]+\"_1440_76_10to25_20mn_0s_128/\"\n",
    "\n",
    "            time = pd.read_csv(pathresults + path2file + \"time.txt\", names = [\"time\",\"Qlight\"])[\"time\"][1:] # because we have twice the initial value\n",
    "            timemax = int((max(time))*10)/10\n",
    "            print('timemax',timemax, timemax==25)\n",
    "            \n",
    "            if(timemax==25):\n",
    "                timeLineNeg, timeLinePos = getTimeLine(path2file, evalTime)\n",
    "                rr = getCylIdx(path2file, timeLinePos)\n",
    "\n",
    "                rr.sort()\n",
    "                print('(',len(rr),')',end =\", \")\n",
    "\n",
    "                for cid in range(nKonz):\n",
    "                    Ginits = np.array([getData_( cid, \n",
    "                                                gId,path2file, timeLineNeg) for gId in rr])          \n",
    "                    GiniAll[cid][pSet] = Ginits\n",
    "                for cid in range(nKonz,volIdx):\n",
    "                    nodes_ = get_last_line_as_numpy_array(path2file+\"nodes_\"+dictXYZ[cid]+\".txt\", timeLinePos,pos = True, dtype =float)\n",
    "                    GiniAll[cid][pSet] = nodes_[rr+1]#seg idx to y-idx\n",
    "                #cid = nToGet -1\n",
    "                Ginits = np.array([getData_( volIdx, gId,path2file, timeLineNeg) for gId in rr])\n",
    "                GiniAll[volIdx][pSet] = Ginits\n",
    "                \n",
    "                Ginits = np.array([getData_( coordId, gId,path2file, timeLineNeg) for gId in rr])\n",
    "                GiniAll[coordId][pSet] = Ginits\n",
    "                \n",
    "                \n",
    "                lens = get_last_line_as_numpy_array(path2file+\"length_Segs\"+\".txt\", timeLinePos,pos = True, dtype =float, verbose = True)\n",
    "                GiniAll[lenIdx][pSet] = lens[rr]\n",
    "                sts = get_last_line_as_numpy_array(path2file+\"subTypes\"+\".txt\", timeLinePos,pos = True, dtype =float, verbose = True)\n",
    "                assert len(sts) == len(lens)\n",
    "                GiniAll[stIdx][pSet] = sts[rr]\n",
    "\n",
    "                orgidPerNode = get_last_line_as_numpy_array(path2file+\"orgidPerNode.txt\", timeLinePos,pos = True, dtype =int, verbose = True)\n",
    "                globalNodeId = get_last_line_as_numpy_array(path2file+\"globalNodeId.txt\", timeLinePos,pos = True, dtype =int, verbose = True)\n",
    "                parentNidx = get_last_line_as_numpy_array(path2file+\"parentNidx.txt\", timeLinePos, pos = True,dtype =int, verbose = True)\n",
    "                ot_orgs = get_last_line_as_numpy_array(path2file+\"ot_orgs.txt\", timeLinePos,pos = True, dtype =int, verbose = True)\n",
    "                id_orgs = get_last_line_as_numpy_array(path2file+\"id_orgs.txt\", timeLinePos, pos = True,\n",
    "                                                       dtype =int, verbose = True)\n",
    "                id_roots = id_orgs[np.where(ot_orgs==2)]\n",
    "\n",
    "                org2basenode = dict(zip(id_orgs, parentNidx))\n",
    "                #org2ot = dict(zip(id_orgs, ot_orgs))\n",
    "                isRoot = np.array([oo in id_roots for oo in orgidPerNode])\n",
    "\n",
    "                orgidPerRoot = orgidPerNode[np.where(isRoot)]\n",
    "                globalNodeIdroot =  globalNodeId[np.where(isRoot)]        \n",
    "                segIdxRoot = np.array([rr for _, rr in enumerate(globalNodeIdroot) if rr != org2basenode[orgidPerRoot[_]]]) -1\n",
    "                orgIdxRoot = np.array([orgidPerRoot[_] for _, rr in enumerate(globalNodeIdroot) if rr != org2basenode[orgidPerRoot[_]]])\n",
    "                #segIdx2ot = dict(zip(segIdxRoot,orgIdxRoot))\n",
    "\n",
    "                relLens = np.zeros(len(segIdxRoot))\n",
    "                #lens = get_last_line_as_numpy_array(path2file+\"length_Segs\"+\".txt\", dtype =float)\n",
    "                for myorg in orgIdxRoot:\n",
    "                    thensegs = np.where(orgIdxRoot == myorg)#segIdxRoot[] \n",
    "                    lenSegs = GiniAll[lenIdx][pSet]\n",
    "                    relLens[thensegs] = np.cumsum(lenSegs[thensegs])\n",
    "\n",
    "\n",
    "                GiniAll[orgIdId][pSet] = orgIdxRoot\n",
    "                GiniAll[relLenId][pSet] = relLens\n",
    "\n",
    "            #except:\n",
    "            #    print('jump',end =\", \")\n",
    "\n",
    "    return GiniAll #cid pSet rr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7924bb88-81aa-435d-a182-eaddbd611fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, timemax 25.0 True\n",
      "timeLine 1 1079 4.227729277772596e-13\n",
      "getsrivssriset/earlyDry_1476_5_10to25_20mn_0s_64/rhizoSegsId.txt 457, rhizoSegsId 514\n",
      "( 457 ), getsrivssriset/earlyDry_1476_5_10to25_20mn_0s_64/length_Segs.txt 515, getsrivssriset/earlyDry_1476_5_10to25_20mn_0s_64/subTypes.txt 515, getsrivssriset/earlyDry_1476_5_10to25_20mn_0s_64/orgidPerNode.txt 515, getsrivssriset/earlyDry_1476_5_10to25_20mn_0s_64/globalNodeId.txt 515, getsrivssriset/earlyDry_1476_5_10to25_20mn_0s_64/parentNidx.txt 217, getsrivssriset/earlyDry_1476_5_10to25_20mn_0s_64/ot_orgs.txt 217, getsrivssriset/earlyDry_1476_5_10to25_20mn_0s_64/id_orgs.txt 217, 1, timemax 25.0 True\n",
      "timeLine 1 1079 4.227729277772596e-13\n",
      "getsrivssriset/earlyDry_1476_44_10to25_20mn_0s_64/rhizoSegsId.txt 458, rhizoSegsId 515\n",
      "( 458 ), getsrivssriset/earlyDry_1476_44_10to25_20mn_0s_64/length_Segs.txt 516, getsrivssriset/earlyDry_1476_44_10to25_20mn_0s_64/subTypes.txt 516, getsrivssriset/earlyDry_1476_44_10to25_20mn_0s_64/orgidPerNode.txt 516, getsrivssriset/earlyDry_1476_44_10to25_20mn_0s_64/globalNodeId.txt 516, getsrivssriset/earlyDry_1476_44_10to25_20mn_0s_64/parentNidx.txt 217, getsrivssriset/earlyDry_1476_44_10to25_20mn_0s_64/ot_orgs.txt 217, getsrivssriset/earlyDry_1476_44_10to25_20mn_0s_64/id_orgs.txt 217, 2, timemax 25.0 True\n",
      "timeLine 1 1079 4.227729277772596e-13\n",
      "getsrivssriset/earlyDry_1476_61_10to25_20mn_0s_64/rhizoSegsId.txt 458, rhizoSegsId 515\n",
      "( 458 ), getsrivssriset/earlyDry_1476_61_10to25_20mn_0s_64/length_Segs.txt 516, getsrivssriset/earlyDry_1476_61_10to25_20mn_0s_64/subTypes.txt 516, getsrivssriset/earlyDry_1476_61_10to25_20mn_0s_64/orgidPerNode.txt 516, getsrivssriset/earlyDry_1476_61_10to25_20mn_0s_64/globalNodeId.txt 516, getsrivssriset/earlyDry_1476_61_10to25_20mn_0s_64/parentNidx.txt 217, getsrivssriset/earlyDry_1476_61_10to25_20mn_0s_64/ot_orgs.txt 217, getsrivssriset/earlyDry_1476_61_10to25_20mn_0s_64/id_orgs.txt 217, 3, timemax 25.0 True\n",
      "timeLine 1 1079 4.227729277772596e-13\n",
      "getsrivssriset/baseline_1476_5_10to25_20mn_0s_64/rhizoSegsId.txt 1005, rhizoSegsId 1095\n",
      "( 1005 ), getsrivssriset/baseline_1476_5_10to25_20mn_0s_64/length_Segs.txt 1096, getsrivssriset/baseline_1476_5_10to25_20mn_0s_64/subTypes.txt 1096, getsrivssriset/baseline_1476_5_10to25_20mn_0s_64/orgidPerNode.txt 1096, getsrivssriset/baseline_1476_5_10to25_20mn_0s_64/globalNodeId.txt 1096, getsrivssriset/baseline_1476_5_10to25_20mn_0s_64/parentNidx.txt 496, getsrivssriset/baseline_1476_5_10to25_20mn_0s_64/ot_orgs.txt 496, getsrivssriset/baseline_1476_5_10to25_20mn_0s_64/id_orgs.txt 496, 4, timemax 25.0 True\n",
      "timeLine 1 1079 4.227729277772596e-13\n",
      "getsrivssriset/baseline_1476_44_10to25_20mn_0s_64/rhizoSegsId.txt 1005, rhizoSegsId 1095\n",
      "( 1005 ), getsrivssriset/baseline_1476_44_10to25_20mn_0s_64/length_Segs.txt 1096, getsrivssriset/baseline_1476_44_10to25_20mn_0s_64/subTypes.txt 1096, getsrivssriset/baseline_1476_44_10to25_20mn_0s_64/orgidPerNode.txt 1096, getsrivssriset/baseline_1476_44_10to25_20mn_0s_64/globalNodeId.txt 1096, getsrivssriset/baseline_1476_44_10to25_20mn_0s_64/parentNidx.txt 496, getsrivssriset/baseline_1476_44_10to25_20mn_0s_64/ot_orgs.txt 496, getsrivssriset/baseline_1476_44_10to25_20mn_0s_64/id_orgs.txt 496, 5, timemax 25.0 True\n",
      "timeLine 1 1079 4.227729277772596e-13\n",
      "getsrivssriset/baseline_1476_61_10to25_20mn_0s_64/rhizoSegsId.txt 1005, rhizoSegsId 1095\n",
      "( 1005 ), getsrivssriset/baseline_1476_61_10to25_20mn_0s_64/length_Segs.txt 1096, getsrivssriset/baseline_1476_61_10to25_20mn_0s_64/subTypes.txt 1096, getsrivssriset/baseline_1476_61_10to25_20mn_0s_64/orgidPerNode.txt 1096, getsrivssriset/baseline_1476_61_10to25_20mn_0s_64/globalNodeId.txt 1096, getsrivssriset/baseline_1476_61_10to25_20mn_0s_64/parentNidx.txt 496, getsrivssriset/baseline_1476_61_10to25_20mn_0s_64/ot_orgs.txt 496, getsrivssriset/baseline_1476_61_10to25_20mn_0s_64/id_orgs.txt 496, 6, timemax 25.0 True\n",
      "timeLine 1 1079 4.227729277772596e-13\n",
      "getsrivssriset/lateDry_1476_5_10to25_20mn_0s_64/rhizoSegsId.txt 385, rhizoSegsId 432\n",
      "( 385 ), getsrivssriset/lateDry_1476_5_10to25_20mn_0s_64/length_Segs.txt 433, getsrivssriset/lateDry_1476_5_10to25_20mn_0s_64/subTypes.txt 433, getsrivssriset/lateDry_1476_5_10to25_20mn_0s_64/orgidPerNode.txt 433, getsrivssriset/lateDry_1476_5_10to25_20mn_0s_64/globalNodeId.txt 433, getsrivssriset/lateDry_1476_5_10to25_20mn_0s_64/parentNidx.txt 166, getsrivssriset/lateDry_1476_5_10to25_20mn_0s_64/ot_orgs.txt 166, getsrivssriset/lateDry_1476_5_10to25_20mn_0s_64/id_orgs.txt 166, 7, timemax 25.0 True\n",
      "timeLine 1 1079 4.227729277772596e-13\n",
      "getsrivssriset/lateDry_1476_44_10to25_20mn_0s_64/rhizoSegsId.txt 385, rhizoSegsId 432\n",
      "( 385 ), getsrivssriset/lateDry_1476_44_10to25_20mn_0s_64/length_Segs.txt 433, getsrivssriset/lateDry_1476_44_10to25_20mn_0s_64/subTypes.txt 433, getsrivssriset/lateDry_1476_44_10to25_20mn_0s_64/orgidPerNode.txt 433, getsrivssriset/lateDry_1476_44_10to25_20mn_0s_64/globalNodeId.txt 433, getsrivssriset/lateDry_1476_44_10to25_20mn_0s_64/parentNidx.txt 166, getsrivssriset/lateDry_1476_44_10to25_20mn_0s_64/ot_orgs.txt 166, getsrivssriset/lateDry_1476_44_10to25_20mn_0s_64/id_orgs.txt 166, 8, timemax 25.0 True\n",
      "timeLine 1 1079 4.227729277772596e-13\n",
      "getsrivssriset/lateDry_1476_61_10to25_20mn_0s_64/rhizoSegsId.txt 385, rhizoSegsId 432\n",
      "( 385 ), getsrivssriset/lateDry_1476_61_10to25_20mn_0s_64/length_Segs.txt 433, getsrivssriset/lateDry_1476_61_10to25_20mn_0s_64/subTypes.txt 433, getsrivssriset/lateDry_1476_61_10to25_20mn_0s_64/orgidPerNode.txt 433, getsrivssriset/lateDry_1476_61_10to25_20mn_0s_64/globalNodeId.txt 433, getsrivssriset/lateDry_1476_61_10to25_20mn_0s_64/parentNidx.txt 166, getsrivssriset/lateDry_1476_61_10to25_20mn_0s_64/ot_orgs.txt 166, getsrivssriset/lateDry_1476_61_10to25_20mn_0s_64/id_orgs.txt 166, "
     ]
    }
   ],
   "source": [
    "\n",
    "GiniAll = getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b496ee2-29a8-4b57-8fdd-700d6444c20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GiniAll_ =GiniAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "889450cc-4753-4a8c-8d23-bc1649492bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "g_cylindx = [[] for i in range(len(allPSets))]\n",
    "for pp in range(len(allPSets)):\n",
    "    numSeg = len(GiniAll[orgIdId][pp])\n",
    "    g_cylindx[pp] = np.array([rr for rr in range(numSeg)] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a13e3127-ac2f-4bb8-b659-714880c1da32",
   "metadata": {},
   "outputs": [],
   "source": [
    "GiniAll.append(g_cylindx)\n",
    "df = pd.DataFrame(GiniAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b251c7a-fa13-4523-bc97-be1d8329306b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [[0.0006817294260771512, 0.000959653428732712,...\n",
       "1     [[2.8486815735298076e-06, 2.84867947627166e-06...\n",
       "2     [[0.0005915265795148129, 0.0005915056695894194...\n",
       "3     [[1.1226480088381245e-07, 1.118811300196757e-0...\n",
       "4     [[9.194713284194991e-06, 9.194932855723927e-06...\n",
       "5     [[1.0808634899075511e-07, 1.0805647313594791e-...\n",
       "6     [[9.495175223481356e-06, 9.492576502558687e-06...\n",
       "7     [[6.567094140939179e-05, 6.567087197882797e-05...\n",
       "8     [[4.24630068178538e-05, 4.221540397626501e-05,...\n",
       "9     [-0.29843419619737527, 0.04392226409042643, -0...\n",
       "10    [-0.3048545919249007, -0.540902871740023, -0.6...\n",
       "11    [-1.2044339159509272, -2.113869600150491, -2.9...\n",
       "12    [[0.00320187148889538, 0.004507194255000854, 0...\n",
       "13    [1.0, 0.9999999999999999, 1.0, 1.0000000000000...\n",
       "14    [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...\n",
       "15    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
       "16    [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, ...\n",
       "17    [[0.0546613694441331, 0.06485324293618723, 0.0...\n",
       "18    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18160a9a-1015-49ca-8f1c-743866181e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(GiniAll)\n",
    "df.to_pickle('./4pallcellat25.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ee5488-8774-42c6-9028-257a3e97fe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80bd6820-d8bd-40b6-9753-0df6c58e4069",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataInput =  [(scenario, str(setId)) for scenario in scenarios for setId in setIds if (scenario, str(setId)) not in exceptPset ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3d081bb-59cd-418b-a452-8a7ca1620904",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot set a frame with no defined index and a value that cannot be converted to a Series",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py:3892\u001b[0m, in \u001b[0;36mDataFrame._ensure_valid_index\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3892\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3893\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/series.py:451\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 451\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m     manager \u001b[38;5;241m=\u001b[39m get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.data_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/construction.py:601\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure, allow_2d)\u001b[0m\n\u001b[1;32m    599\u001b[0m             subarr \u001b[38;5;241m=\u001b[39m maybe_infer_to_datetimelike(subarr)\n\u001b[0;32m--> 601\u001b[0m subarr \u001b[38;5;241m=\u001b[39m \u001b[43m_sanitize_ndim\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_2d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(subarr, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;66;03m# at this point we should have dtype be None or subarr.dtype == dtype\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/construction.py:652\u001b[0m, in \u001b[0;36m_sanitize_ndim\u001b[0;34m(result, data, dtype, index, allow_2d)\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m--> 652\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData must be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype):\n\u001b[1;32m    654\u001b[0m     \u001b[38;5;66;03m# i.e. PandasDtype(\"O\")\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Data must be 1-dimensional",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m rows_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m jj, outVn \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(outputvalsname):\n\u001b[0;32m---> 14\u001b[0m     \u001b[43mrows_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43moutVn\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m GiniAll[jj][pset]\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m#print('adding',jj,outVn,duplicated_rows_df.shape,len(GiniAll[jj][pset]))\u001b[39;00m\n\u001b[1;32m     16\u001b[0m rows_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscenario\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m din[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py:3655\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3652\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3653\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3654\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py:3832\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3822\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3823\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3824\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   3825\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3830\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   3831\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3832\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3834\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3835\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   3836\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   3837\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   3838\u001b[0m     ):\n\u001b[1;32m   3839\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   3840\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py:4531\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4518\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sanitize_column\u001b[39m(\u001b[38;5;28mself\u001b[39m, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[1;32m   4519\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4520\u001b[0m \u001b[38;5;124;03m    Ensures new columns (which go into the BlockManager as new blocks) are\u001b[39;00m\n\u001b[1;32m   4521\u001b[0m \u001b[38;5;124;03m    always copied and converted into an array.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4529\u001b[0m \u001b[38;5;124;03m    numpy.ndarray or ExtensionArray\u001b[39;00m\n\u001b[1;32m   4530\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4531\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_valid_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4533\u001b[0m     \u001b[38;5;66;03m# We can get there through loc single_block_path\u001b[39;00m\n\u001b[1;32m   4534\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, (DataFrame, Series)):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py:3894\u001b[0m, in \u001b[0;36mDataFrame._ensure_valid_index\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   3892\u001b[0m         value \u001b[38;5;241m=\u001b[39m Series(value)\n\u001b[1;32m   3893\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3894\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3895\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot set a frame with no defined index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3896\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand a value that cannot be converted to a Series\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3897\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3899\u001b[0m \u001b[38;5;66;03m# GH31368 preserve name of index\u001b[39;00m\n\u001b[1;32m   3900\u001b[0m index_copy \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mcopy()\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot set a frame with no defined index and a value that cannot be converted to a Series"
     ]
    }
   ],
   "source": [
    "# get param set\n",
    "\n",
    "outputvalsname =  ['wat','cs','cl','coa','cod','cca','ccd','co2','css2','yX','yY','yZ','vol','lenSeg','st','orgId','relLen', 'coord']\n",
    "assert len(outputvalsname) == nToGet \n",
    "column_names = outputvalsname + ['scenario']\n",
    "df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "for pset, din in enumerate(dataInput):#range(numPset):\n",
    "    N = GiniAll[0][pset].shape[0]\n",
    "    #assert N == 232\n",
    "    rows_df = pd.DataFrame()\n",
    "\n",
    "    for jj, outVn in enumerate(outputvalsname):\n",
    "        rows_df[outVn] = GiniAll[jj][pset]\n",
    "        #print('adding',jj,outVn,duplicated_rows_df.shape,len(GiniAll[jj][pset]))\n",
    "    rows_df['scenario'] = din[0]\n",
    "    rows_df['pSet'] = din[1]\n",
    "\n",
    "    df = pd.concat([df, rows_df], ignore_index=True)\n",
    "df['co'] = df['coa']+df['cod']\n",
    "df['cc'] = df['cca']+df['ccd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c06e6c67-fce5-46e5-b0c3-c2d2b50c732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('./4paramTemp.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6d03f36-cd15-4e19-8c95-8dc367b98ca9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c70cee0d-57a7-4a43-b920-55f3a3d356cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nToGet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e940a1e-4bbb-4d98-b576-351f99bc8de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(  ['wat','cs','cl','coa','cod','cca','ccd','co2','yX','yY','yZ','vol','lenSeg','st','orgId','relLen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de789fb-db5b-43fc-ba2e-db42473d2db5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38b",
   "language": "python",
   "name": "py38b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
